<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Statistical Identification · MacroEconometricModels.jl</title><meta name="title" content="Statistical Identification · MacroEconometricModels.jl"/><meta property="og:title" content="Statistical Identification · MacroEconometricModels.jl"/><meta property="twitter:title" content="Statistical Identification · MacroEconometricModels.jl"/><meta name="description" content="Documentation for MacroEconometricModels.jl."/><meta property="og:description" content="Documentation for MacroEconometricModels.jl."/><meta property="twitter:description" content="Documentation for MacroEconometricModels.jl."/><meta property="og:url" content="https://FriedmanJP.github.io/MacroEconometricModels.jl/nongaussian/"/><meta property="twitter:url" content="https://FriedmanJP.github.io/MacroEconometricModels.jl/nongaussian/"/><link rel="canonical" href="https://FriedmanJP.github.io/MacroEconometricModels.jl/nongaussian/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/custom.css" rel="stylesheet" type="text/css"/><script src="../assets/theme-toggle.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">MacroEconometricModels.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../data/">Data Management</a></li><li><span class="tocitem">Univariate Models</span><ul><li><a class="tocitem" href="../filters/">Time Series Filters</a></li><li><a class="tocitem" href="../arima/">ARIMA</a></li><li><a class="tocitem" href="../volatility/">Volatility Models</a></li></ul></li><li><span class="tocitem">Multivariate Models</span><ul><li><a class="tocitem" href="../manual/">VAR</a></li><li><a class="tocitem" href="../bayesian/">Bayesian VAR</a></li><li><a class="tocitem" href="../vecm/">VECM</a></li><li><a class="tocitem" href="../lp/">Local Projections</a></li><li><a class="tocitem" href="../factormodels/">Factor Models</a></li></ul></li><li><span class="tocitem">Panel Models</span><ul><li><a class="tocitem" href="../pvar/">Panel VAR</a></li></ul></li><li><a class="tocitem" href="../innovation_accounting/">Innovation Accounting</a></li><li><a class="tocitem" href="../nowcast/">Nowcasting</a></li><li class="is-active"><a class="tocitem" href>Statistical Identification</a><ul class="internal"><li><a class="tocitem" href="#Quick-Start"><span>Quick Start</span></a></li><li><a class="tocitem" href="#The-SVAR-Setting"><span>The SVAR Setting</span></a></li><li><a class="tocitem" href="#Identification-via-Heteroskedasticity"><span>Identification via Heteroskedasticity</span></a></li><li><a class="tocitem" href="#Identification-via-Non-Gaussianity"><span>Identification via Non-Gaussianity</span></a></li><li><a class="tocitem" href="#Multivariate-Normality-Tests"><span>Multivariate Normality Tests</span></a></li><li><a class="tocitem" href="#Identifiability-and-Specification-Tests"><span>Identifiability and Specification Tests</span></a></li><li><a class="tocitem" href="#Integration-with-IRF-Pipeline"><span>Integration with IRF Pipeline</span></a></li><li><a class="tocitem" href="#The-Labeling-Problem"><span>The Labeling Problem</span></a></li><li><a class="tocitem" href="#Complete-Example"><span>Complete Example</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../hypothesis_tests/">Hypothesis Tests</a></li><li><a class="tocitem" href="../plotting/">Visualization</a></li><li><a class="tocitem" href="../examples/">Examples</a></li><li><span class="tocitem">API Reference</span><ul><li><a class="tocitem" href="../api/">Overview</a></li><li><a class="tocitem" href="../api_types/">Types</a></li><li><a class="tocitem" href="../api_functions/">Functions</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Statistical Identification</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Statistical Identification</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/FriedmanJP/MacroEconometricModels.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/FriedmanJP/MacroEconometricModels.jl/blob/main/docs/src/nongaussian.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Statistical-Identification-via-Higher-Moments"><a class="docs-heading-anchor" href="#Statistical-Identification-via-Higher-Moments">Statistical Identification via Higher Moments</a><a id="Statistical-Identification-via-Higher-Moments-1"></a><a class="docs-heading-anchor-permalink" href="#Statistical-Identification-via-Higher-Moments" title="Permalink"></a></h1><p>This page covers identification of structural VAR models using statistical properties beyond second moments: <strong>heteroskedasticity</strong> (time-varying variances) and <strong>non-Gaussianity</strong> (higher-order moments). These methods provide identification without requiring the recursive ordering of Cholesky or the a priori sign/zero restrictions of traditional SVAR.</p><p>The classification follows Lewis (2025), which provides the definitive taxonomy of statistical identification in macroeconometrics. The key insight is that the standard reduced-form covariance <span>$\Sigma = B_0 B_0&#39;$</span> provides only <span>$n(n+1)/2$</span> equations for <span>$n^2$</span> unknowns in <span>$B_0$</span>. The two strands of statistical identification resolve this in complementary ways:</p><ol><li><strong>Heteroskedasticity</strong> (Section 2): exploits <em>multiple</em> covariance matrices from different volatility regimes</li><li><strong>Non-Gaussianity</strong> (Section 3): exploits higher-moment conditions (coskewness, cokurtosis) from non-Gaussian shocks</li></ol><h2 id="Quick-Start"><a class="docs-heading-anchor" href="#Quick-Start">Quick Start</a><a id="Quick-Start-1"></a><a class="docs-heading-anchor-permalink" href="#Quick-Start" title="Permalink"></a></h2><pre><code class="language-julia hljs">using MacroEconometricModels

# Multivariate normality tests (diagnostics)
suite = normality_test_suite(model)                # Run all 7 tests
jb = jarque_bera_test(model)                       # Multivariate Jarque-Bera

# Non-Gaussianity: ICA-based identification
ica = identify_fastica(model)                      # FastICA (Hyvärinen 1999)
jade = identify_jade(model)                        # JADE (Cardoso 1993)

# Non-Gaussianity: ML identification
ml = identify_student_t(model)                     # Student-t shocks
ml = identify_nongaussian_ml(model; distribution=:mixture_normal)

# Heteroskedasticity: regime-based identification
ms = identify_markov_switching(model; n_regimes=2) # Markov-switching (Lanne &amp; Lütkepohl 2008)
ev = identify_external_volatility(model, regime)   # Known volatility regimes (Rigobon 2003)

# Identifiability tests
test_shock_gaussianity(ica)                        # Are shocks non-Gaussian?
test_gaussian_vs_nongaussian(model)                # LR test: Gaussian vs non-Gaussian
test_shock_independence(ica)                       # Are shocks independent?

# Integration with existing IRF pipeline
irfs = irf(model, 20; method=:fastica)             # Works automatically via compute_Q</code></pre><hr/><h2 id="The-SVAR-Setting"><a class="docs-heading-anchor" href="#The-SVAR-Setting">The SVAR Setting</a><a id="The-SVAR-Setting-1"></a><a class="docs-heading-anchor-permalink" href="#The-SVAR-Setting" title="Permalink"></a></h2><p>The structural VAR has the decomposition:</p><p class="math-container">\[u_t = B_0 \varepsilon_t, \quad \Sigma = B_0 B_0&#39;\]</p><p>where</p><ul><li><span>$u_t$</span> is the <span>$n \times 1$</span> vector of reduced-form residuals</li><li><span>$\varepsilon_t$</span> is the <span>$n \times 1$</span> vector of structural shocks (unit variance, mutually independent)</li><li><span>$B_0$</span> is the <span>$n \times n$</span> structural impact matrix</li></ul><p>The reduced-form covariance <span>$\Sigma = B_0 B_0&#39;$</span> provides <span>$n(n+1)/2$</span> equations for <span>$n^2$</span> unknowns in <span>$B_0$</span>, leaving <span>$n(n-1)/2$</span> free parameters. Traditional approaches (Cholesky, sign/zero restrictions) resolve this by imposing economic constraints. Statistical identification takes a different path:</p><ul><li><strong>Heteroskedasticity</strong>: if shock variances change across regimes, each regime provides a <em>separate</em> covariance equation <span>$\Sigma_k = B_0 \Lambda_k B_0&#39;$</span>, generating enough equations to identify <span>$B_0$</span></li><li><strong>Non-Gaussianity</strong>: if shocks are non-Gaussian, independence imposes conditions beyond uncorrelatedness — coskewness, cokurtosis, and higher moments pin down <span>$B_0$</span></li></ul><div class="admonition is-info" id="Technical-Note-f9d0c71d2409bac4"><header class="admonition-header">Technical Note<a class="admonition-anchor" href="#Technical-Note-f9d0c71d2409bac4" title="Permalink"></a></header><div class="admonition-body"><p>Lewis (2025) shows that identification via non-Gaussianity can be thought of as a special case of identification based on heteroskedasticity (p. 674). The Darmois-Skitovich theorem (Comon 1994) establishes that if at most one component is Gaussian and shocks are independent, <span>$B_0$</span> is unique up to column permutation and sign.</p></div></div><hr/><h2 id="Identification-via-Heteroskedasticity"><a class="docs-heading-anchor" href="#Identification-via-Heteroskedasticity">Identification via Heteroskedasticity</a><a id="Identification-via-Heteroskedasticity-1"></a><a class="docs-heading-anchor-permalink" href="#Identification-via-Heteroskedasticity" title="Permalink"></a></h2><p><em>&quot;If variances of structural shocks change through time, then there is not just a single reduced-form covariance matrix to exploit.&quot;</em> — Lewis (2025, Section 3)</p><p>When the structural shock variances change across <span>$K$</span> regimes while <span>$B_0$</span> remains constant, we have:</p><p class="math-container">\[\Sigma_k = B_0 \Lambda_k B_0&#39;, \quad k = 1, \ldots, K\]</p><p>where <span>$\Lambda_k = \text{diag}(\lambda_{1k}, \ldots, \lambda_{nk})$</span> are regime-specific variance matrices. With <span>$K \geq 2$</span> regimes, the eigendecomposition of <span>$\Sigma_1^{-1} \Sigma_2$</span> identifies <span>$B_0$</span> up to column permutation and sign, provided eigenvalues are distinct (Rigobon 2003).</p><h3 id="Eigendecomposition-Identification"><a class="docs-heading-anchor" href="#Eigendecomposition-Identification">Eigendecomposition Identification</a><a id="Eigendecomposition-Identification-1"></a><a class="docs-heading-anchor-permalink" href="#Eigendecomposition-Identification" title="Permalink"></a></h3><p>The core idea (Rigobon 2003): given two regime covariance matrices <span>$\Sigma_1$</span> and <span>$\Sigma_2$</span>, the eigendecomposition of <span>$\Sigma_1^{-1}\Sigma_2$</span> yields:</p><p class="math-container">\[\Sigma_1^{-1}\Sigma_2 = V D V^{-1}\]</p><p>where</p><ul><li><span>$V$</span> contains the eigenvectors</li><li><span>$D = \text{diag}(\lambda_1, \ldots, \lambda_n)$</span> contains the relative variance ratios</li><li><span>$B_0 = \Sigma_1^{1/2} V$</span> (with normalization)</li></ul><p><strong>Identification condition</strong>: The eigenvalues <span>$\lambda_j$</span> must be distinct.</p><h3 id="Markov-Switching-Volatility"><a class="docs-heading-anchor" href="#Markov-Switching-Volatility">Markov-Switching Volatility</a><a id="Markov-Switching-Volatility-1"></a><a class="docs-heading-anchor-permalink" href="#Markov-Switching-Volatility" title="Permalink"></a></h3><p>Estimates regime-specific covariance matrices via the Hamilton (1989) filter with EM algorithm:</p><pre><code class="language-julia hljs">using MacroEconometricModels

# Load FRED-MD monetary policy model
fred = load_example(:fred_md)
Y = to_matrix(apply_tcode(fred[:, [&quot;INDPRO&quot;, &quot;CPIAUCSL&quot;, &quot;FEDFUNDS&quot;]]))
Y = Y[all.(isfinite, eachrow(Y)), :]
model = estimate_var(Y, 2)

ms = identify_markov_switching(model; n_regimes=2)
println(&quot;Transition matrix:&quot;)
println(round.(ms.transition_matrix, digits=3))
println(&quot;Regime probabilities (first 5 obs):&quot;)
println(round.(ms.regime_probs[1:5, :], digits=3))</code></pre><p>The EM algorithm iterates:</p><ol><li><strong>E-step</strong>: Hamilton filter (forward) + Kim (1994) joint smoother (backward) → regime probabilities</li><li><strong>M-step</strong>: Update regime covariances and transition matrix given smoothed joint probabilities <span>$\xi_{t,t-1|T}(i,j)$</span></li></ol><div class="admonition is-info" id="Kim-(1994)-Joint-Smoother-5e861161d941e83a"><header class="admonition-header">Kim (1994) Joint Smoother<a class="admonition-anchor" href="#Kim-(1994)-Joint-Smoother-5e861161d941e83a" title="Permalink"></a></header><div class="admonition-body"><p>The transition matrix update in the M-step uses the Kim (1994) joint smoother to compute <span>$\xi_{t,t-1|T}(i,j) = P(S_t = j, S_{t-1} = i | Y_T)$</span>. This joint probability combines forward-filtered probabilities with backward-smoothed probabilities to properly account for cross-regime correlations. The naive product <span>$P(S_{t-1}=i|Y_T) \cdot P(S_t=j|Y_T)$</span> ignores serial dependence in regime assignments and can produce biased transition matrix estimates.</p></div></div><p><strong>Reference</strong>: Lanne &amp; Lütkepohl (2008), Kim (1994)</p><h3 id="GARCH-Based-Identification"><a class="docs-heading-anchor" href="#GARCH-Based-Identification">GARCH-Based Identification</a><a id="GARCH-Based-Identification-1"></a><a class="docs-heading-anchor-permalink" href="#GARCH-Based-Identification" title="Permalink"></a></h3><p>Uses GARCH(1,1) conditional heteroskedasticity in the structural shocks for identification. The time-varying conditional variances <span>$h_{j,t}$</span> enter a full time-varying log-likelihood:</p><p class="math-container">\[h_{j,t} = \omega_j + \alpha_j \varepsilon_{j,t-1}^2 + \beta_j h_{j,t-1}\]</p><p>The structural impact matrix <span>$B_0$</span> is estimated by maximizing:</p><p class="math-container">\[\ell(B_0) = -\frac{1}{2} \sum_{t=1}^{T} \left[ n \ln(2\pi) + \sum_{j=1}^{n} \ln h_{j,t} + \sum_{j=1}^{n} \frac{\varepsilon_{j,t}^2}{h_{j,t}} \right]\]</p><p>where <span>$\varepsilon_t = B_0^{-1} u_t$</span> and each <span>$h_{j,t}$</span> is updated using the GARCH recursion with the current <span>$B_0$</span>.</p><pre><code class="language-julia hljs">garch = identify_garch(model)
println(&quot;GARCH parameters (ω, α, β):&quot;)
for j in 1:size(garch.garch_params, 1)
    println(&quot;  Shock $j: &quot;, round.(garch.garch_params[j, :], digits=4))
end</code></pre><p><strong>Reference</strong>: Normandin &amp; Phaneuf (2004)</p><h3 id="Smooth-Transition"><a class="docs-heading-anchor" href="#Smooth-Transition">Smooth Transition</a><a id="Smooth-Transition-1"></a><a class="docs-heading-anchor-permalink" href="#Smooth-Transition" title="Permalink"></a></h3><p>The covariance varies smoothly between two regimes via a logistic transition function:</p><p class="math-container">\[\Sigma_t = B_0 [I + G(s_t)(\Lambda - I)] B_0&#39;\]</p><p>where <span>$G(s_t) = 1/(1 + \exp(-\gamma(s_t - c)))$</span> is the logistic transition function.</p><pre><code class="language-julia hljs"># Use a lagged variable as the transition variable
s = Y[2:end, 1]  # first variable, lagged
st = identify_smooth_transition(model, s)
println(&quot;Transition speed γ = $(round(st.gamma, digits=3))&quot;)
println(&quot;Threshold c = $(round(st.threshold, digits=3))&quot;)</code></pre><p><strong>Reference</strong>: Lütkepohl &amp; Netšunajev (2017)</p><h3 id="External-Volatility-Instruments"><a class="docs-heading-anchor" href="#External-Volatility-Instruments">External Volatility Instruments</a><a id="External-Volatility-Instruments-1"></a><a class="docs-heading-anchor-permalink" href="#External-Volatility-Instruments" title="Permalink"></a></h3><p>When volatility regimes are known a priori (e.g., NBER recession dates, financial crisis indicators):</p><pre><code class="language-julia hljs"># Binary regime indicator
regime = vcat(fill(1, 100), fill(2, 100))  # first half = regime 1
ev = identify_external_volatility(model, regime)</code></pre><p>This is the simplest heteroskedasticity method — it just splits the sample and applies eigendecomposition identification.</p><p><strong>Reference</strong>: Rigobon (2003)</p><h3 id="Heteroskedasticity-Result-Fields"><a class="docs-heading-anchor" href="#Heteroskedasticity-Result-Fields">Heteroskedasticity Result Fields</a><a id="Heteroskedasticity-Result-Fields-1"></a><a class="docs-heading-anchor-permalink" href="#Heteroskedasticity-Result-Fields" title="Permalink"></a></h3><p><strong>Markov-Switching</strong> (<code>MarkovSwitchingSVARResult</code>):</p><table><tr><th style="text-align: right">Field</th><th style="text-align: right">Type</th><th style="text-align: right">Description</th></tr><tr><td style="text-align: right"><code>B0</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Structural impact matrix</td></tr><tr><td style="text-align: right"><code>Q</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Rotation matrix</td></tr><tr><td style="text-align: right"><code>Sigma_regimes</code></td><td style="text-align: right"><code>Vector{Matrix{T}}</code></td><td style="text-align: right">Covariance per regime</td></tr><tr><td style="text-align: right"><code>Lambda</code></td><td style="text-align: right"><code>Vector{Vector{T}}</code></td><td style="text-align: right">Relative variances per regime</td></tr><tr><td style="text-align: right"><code>regime_probs</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Smoothed regime probabilities (T × K)</td></tr><tr><td style="text-align: right"><code>transition_matrix</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Markov transition probabilities (K × K)</td></tr><tr><td style="text-align: right"><code>loglik</code></td><td style="text-align: right"><code>T</code></td><td style="text-align: right">Log-likelihood</td></tr><tr><td style="text-align: right"><code>converged</code></td><td style="text-align: right"><code>Bool</code></td><td style="text-align: right">Convergence status</td></tr><tr><td style="text-align: right"><code>n_regimes</code></td><td style="text-align: right"><code>Int</code></td><td style="text-align: right">Number of regimes</td></tr></table><p><strong>GARCH</strong> (<code>GARCHSVARResult</code>):</p><table><tr><th style="text-align: right">Field</th><th style="text-align: right">Type</th><th style="text-align: right">Description</th></tr><tr><td style="text-align: right"><code>B0</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Structural impact matrix</td></tr><tr><td style="text-align: right"><code>Q</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Rotation matrix</td></tr><tr><td style="text-align: right"><code>garch_params</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">(n × 3): [ω, α, β] per shock</td></tr><tr><td style="text-align: right"><code>cond_var</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">(T × n) conditional variances</td></tr><tr><td style="text-align: right"><code>shocks</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Structural shocks</td></tr><tr><td style="text-align: right"><code>loglik</code></td><td style="text-align: right"><code>T</code></td><td style="text-align: right">Log-likelihood</td></tr></table><p><strong>Smooth Transition</strong> (<code>SmoothTransitionSVARResult</code>):</p><table><tr><th style="text-align: right">Field</th><th style="text-align: right">Type</th><th style="text-align: right">Description</th></tr><tr><td style="text-align: right"><code>B0</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Structural impact matrix</td></tr><tr><td style="text-align: right"><code>gamma</code></td><td style="text-align: right"><code>T</code></td><td style="text-align: right">Transition speed parameter</td></tr><tr><td style="text-align: right"><code>threshold</code></td><td style="text-align: right"><code>T</code></td><td style="text-align: right">Transition location parameter</td></tr><tr><td style="text-align: right"><code>G_values</code></td><td style="text-align: right"><code>Vector{T}</code></td><td style="text-align: right">Transition function values</td></tr></table><p><strong>External Volatility</strong> (<code>ExternalVolatilitySVARResult</code>):</p><table><tr><th style="text-align: right">Field</th><th style="text-align: right">Type</th><th style="text-align: right">Description</th></tr><tr><td style="text-align: right"><code>B0</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Structural impact matrix</td></tr><tr><td style="text-align: right"><code>Sigma_regimes</code></td><td style="text-align: right"><code>Vector{Matrix{T}}</code></td><td style="text-align: right">Covariance per regime</td></tr><tr><td style="text-align: right"><code>Lambda</code></td><td style="text-align: right"><code>Vector{Vector{T}}</code></td><td style="text-align: right">Relative variances per regime</td></tr><tr><td style="text-align: right"><code>regime_indices</code></td><td style="text-align: right"><code>Vector{Vector{Int}}</code></td><td style="text-align: right">Observation indices per regime</td></tr></table><hr/><h2 id="Identification-via-Non-Gaussianity"><a class="docs-heading-anchor" href="#Identification-via-Non-Gaussianity">Identification via Non-Gaussianity</a><a id="Identification-via-Non-Gaussianity-1"></a><a class="docs-heading-anchor-permalink" href="#Identification-via-Non-Gaussianity" title="Permalink"></a></h2><p><em>&quot;Identification via non-Gaussianity can be thought of as a special case of identification based on heteroskedasticity.&quot;</em> — Lewis (2025, p. 674)</p><p>The Darmois-Skitovich theorem establishes that if <span>$\varepsilon_t$</span> has independent components and at most one is Gaussian, then the mixing matrix <span>$B_0$</span> is unique up to column permutation and sign (Comon 1994). This provides identification from a <em>single</em> sample without requiring volatility changes.</p><h3 id="ICA-Based-Methods-(Nonparametric)"><a class="docs-heading-anchor" href="#ICA-Based-Methods-(Nonparametric)">ICA-Based Methods (Nonparametric)</a><a id="ICA-Based-Methods-(Nonparametric)-1"></a><a class="docs-heading-anchor-permalink" href="#ICA-Based-Methods-(Nonparametric)" title="Permalink"></a></h3><p>Independent Component Analysis (ICA) identifies <span>$B_0$</span> by finding the rotation <span>$Q$</span> that makes the recovered shocks <span>$\varepsilon_t = (B_0)^{-1} u_t$</span> maximally independent and non-Gaussian.</p><h4 id="Model-Specification"><a class="docs-heading-anchor" href="#Model-Specification">Model Specification</a><a id="Model-Specification-1"></a><a class="docs-heading-anchor-permalink" href="#Model-Specification" title="Permalink"></a></h4><p class="math-container">\[u_t = B_0 \varepsilon_t, \quad B_0 = L Q\]</p><p>where <span>$L = \text{chol}(\Sigma)$</span> and <span>$Q$</span> is orthogonal. ICA searches over orthogonal <span>$Q$</span> to maximize a measure of non-Gaussianity or independence.</p><p><strong>Identification condition</strong>: At most one structural shock may be Gaussian (Lanne, Meitz &amp; Saikkonen 2017). If all shocks are non-Gaussian, <span>$B_0$</span> is unique up to column permutation and sign.</p><h4 id="FastICA"><a class="docs-heading-anchor" href="#FastICA">FastICA</a><a id="FastICA-1"></a><a class="docs-heading-anchor-permalink" href="#FastICA" title="Permalink"></a></h4><p>FastICA (Hyvärinen 1999) finds the unmixing matrix by maximizing a measure of non-Gaussianity (negentropy) via a fixed-point algorithm.</p><pre><code class="language-julia hljs"># Default: logcosh contrast, deflation approach
ica = identify_fastica(model)

# Symmetric approach with exponential contrast
ica = identify_fastica(model; approach=:symmetric, contrast=:exp)</code></pre><p>Three contrast functions are available:</p><ul><li><code>:logcosh</code> (default) — robust, good general-purpose choice: <span>$G(u) = \log\cosh(u)$</span></li><li><code>:exp</code> — better for super-Gaussian sources: <span>$G(u) = -\exp(-u^2/2)$</span></li><li><code>:kurtosis</code> — classical kurtosis-based: <span>$G(u) = u^4/4$</span></li></ul><p>Two extraction approaches:</p><ul><li><code>:deflation</code> — extracts components one at a time (deflation approach)</li><li><code>:symmetric</code> — extracts all components simultaneously</li></ul><p><strong>Reference</strong>: Hyvärinen (1999)</p><h4 id="JADE"><a class="docs-heading-anchor" href="#JADE">JADE</a><a id="JADE-1"></a><a class="docs-heading-anchor-permalink" href="#JADE" title="Permalink"></a></h4><p>JADE (Joint Approximate Diagonalization of Eigenmatrices) uses fourth-order cumulant matrices and joint diagonalization via Jacobi rotations.</p><pre><code class="language-julia hljs">jade = identify_jade(model)</code></pre><p>JADE computes the fourth-order cumulant matrices <span>$C_{ij}[k,l] = \text{cum}(z_k, z_l, z_i, z_j)$</span> and finds the orthogonal matrix that simultaneously diagonalizes all of them.</p><p><strong>Reference</strong>: Cardoso &amp; Souloumiac (1993)</p><h4 id="SOBI"><a class="docs-heading-anchor" href="#SOBI">SOBI</a><a id="SOBI-1"></a><a class="docs-heading-anchor-permalink" href="#SOBI" title="Permalink"></a></h4><p>SOBI (Second-Order Blind Identification) exploits temporal structure via autocovariance matrices at multiple lags.</p><pre><code class="language-julia hljs">sobi = identify_sobi(model; lags=1:12)</code></pre><p>Unlike FastICA and JADE which use higher-order statistics, SOBI only uses second-order statistics (autocovariances), making it suitable when temporal dependence is the main source of identifiability.</p><p><strong>Reference</strong>: Belouchrani et al. (1997)</p><h4 id="Distance-Covariance"><a class="docs-heading-anchor" href="#Distance-Covariance">Distance Covariance</a><a id="Distance-Covariance-1"></a><a class="docs-heading-anchor-permalink" href="#Distance-Covariance" title="Permalink"></a></h4><p>Minimizes the sum of pairwise distance covariances between recovered shocks. Distance covariance (Székely et al. 2007) is zero if and only if variables are independent.</p><pre><code class="language-julia hljs">dcov = identify_dcov(model)</code></pre><p><strong>Reference</strong>: Matteson &amp; Tsay (2017)</p><h4 id="HSIC"><a class="docs-heading-anchor" href="#HSIC">HSIC</a><a id="HSIC-1"></a><a class="docs-heading-anchor-permalink" href="#HSIC" title="Permalink"></a></h4><p>Minimizes the Hilbert-Schmidt Independence Criterion using a Gaussian kernel. Like distance covariance, HSIC with a characteristic kernel is zero iff variables are independent.</p><pre><code class="language-julia hljs">hsic = identify_hsic(model; sigma=1.0)</code></pre><p>The bandwidth parameter <span>$\sigma$</span> defaults to the median pairwise distance heuristic.</p><p><strong>Reference</strong>: Gretton et al. (2005)</p><h3 id="Maximum-Likelihood-Methods-(Parametric)"><a class="docs-heading-anchor" href="#Maximum-Likelihood-Methods-(Parametric)">Maximum Likelihood Methods (Parametric)</a><a id="Maximum-Likelihood-Methods-(Parametric)-1"></a><a class="docs-heading-anchor-permalink" href="#Maximum-Likelihood-Methods-(Parametric)" title="Permalink"></a></h3><p>Instead of the two-step ICA approach, ML methods estimate <span>$B_0$</span> and the shock distribution parameters jointly by maximizing the log-likelihood:</p><p class="math-container">\[\ell(\theta) = \sum_{t=1}^T \left[ \log|\det(B_0^{-1})| + \sum_{j=1}^n \log f_j(\varepsilon_{j,t}; \theta_j) \right]\]</p><p>where <span>$f_j(\cdot; \theta_j)$</span> is the marginal density of shock <span>$j$</span> and <span>$\theta_j$</span> are distribution-specific parameters.</p><h4 id="Student-t-Shocks"><a class="docs-heading-anchor" href="#Student-t-Shocks">Student-t Shocks</a><a id="Student-t-Shocks-1"></a><a class="docs-heading-anchor-permalink" href="#Student-t-Shocks" title="Permalink"></a></h4><p>Assumes each shock follows a (standardized) Student-t distribution with shock-specific degrees of freedom <span>$\nu_j$</span>:</p><pre><code class="language-julia hljs">ml = identify_student_t(model)
println(&quot;Degrees of freedom: &quot;, ml.dist_params[:nu])</code></pre><p>Low <span>$\nu$</span> indicates heavy tails. When <span>$\nu \to \infty$</span>, the shock approaches Gaussianity. Identification requires that at most one shock has <span>$\nu = \infty$</span>.</p><p><strong>Reference</strong>: Lanne, Meitz &amp; Saikkonen (2017)</p><h4 id="Mixture-of-Normals"><a class="docs-heading-anchor" href="#Mixture-of-Normals">Mixture of Normals</a><a id="Mixture-of-Normals-1"></a><a class="docs-heading-anchor-permalink" href="#Mixture-of-Normals" title="Permalink"></a></h4><p>Each shock follows a mixture of two normals: <span>$\varepsilon_j \sim p_j N(0, \sigma_{1j}^2) + (1-p_j) N(0, \sigma_{2j}^2)$</span> with the unit variance constraint <span>$p_j \sigma_{1j}^2 + (1-p_j) \sigma_{2j}^2 = 1$</span>.</p><p>The variance <span>$\sigma_{1j}$</span> is internally reparametrized via a sigmoid function <span>$\sigma_{1j}^2 = \text{sigmoid}(\theta) / p_j$</span> to ensure <span>$\sigma_{1j}^2 \in (0, 1/p_j)$</span>, which guarantees <span>$\sigma_{2j}^2 &gt; 0$</span> for all optimizer iterates. The second variance is derived from the unit variance constraint: <span>$\sigma_{2j}^2 = (1 - p_j \sigma_{1j}^2) / (1 - p_j)$</span>.</p><pre><code class="language-julia hljs">ml = identify_mixture_normal(model)
println(&quot;Mixing probabilities: &quot;, ml.dist_params[:p_mix])</code></pre><p><strong>Reference</strong>: Lanne &amp; Lütkepohl (2010)</p><h4 id="Pseudo-Maximum-Likelihood-(PML)"><a class="docs-heading-anchor" href="#Pseudo-Maximum-Likelihood-(PML)">Pseudo Maximum Likelihood (PML)</a><a id="Pseudo-Maximum-Likelihood-(PML)-1"></a><a class="docs-heading-anchor-permalink" href="#Pseudo-Maximum-Likelihood-(PML)" title="Permalink"></a></h4><p>Uses Pearson Type IV distributions, allowing both skewness and excess kurtosis.</p><pre><code class="language-julia hljs">ml = identify_pml(model)</code></pre><p><strong>Reference</strong>: Herwartz (2018)</p><h4 id="Skew-Normal-Shocks"><a class="docs-heading-anchor" href="#Skew-Normal-Shocks">Skew-Normal Shocks</a><a id="Skew-Normal-Shocks-1"></a><a class="docs-heading-anchor-permalink" href="#Skew-Normal-Shocks" title="Permalink"></a></h4><p>Each shock follows a skew-normal distribution with pdf <span>$f(x) = 2\phi(x)\Phi(\alpha_j x)$</span>.</p><pre><code class="language-julia hljs">ml = identify_skew_normal(model)
println(&quot;Skewness parameters: &quot;, ml.dist_params[:alpha])</code></pre><p><strong>Reference</strong>: Azzalini (1985)</p><h4 id="Unified-Dispatcher"><a class="docs-heading-anchor" href="#Unified-Dispatcher">Unified Dispatcher</a><a id="Unified-Dispatcher-1"></a><a class="docs-heading-anchor-permalink" href="#Unified-Dispatcher" title="Permalink"></a></h4><p>Use <code>identify_nongaussian_ml</code> to select the distribution at runtime:</p><pre><code class="language-julia hljs">for dist in [:student_t, :mixture_normal, :pml, :skew_normal]
    ml = identify_nongaussian_ml(model; distribution=dist)
    println(&quot;$dist: logL=$(round(ml.loglik, digits=2)), AIC=$(round(ml.aic, digits=2))&quot;)
end</code></pre><p>Compare AIC/BIC across distributions to select the best-fitting specification.</p><h3 id="Moment-Based-Approaches"><a class="docs-heading-anchor" href="#Moment-Based-Approaches">Moment-Based Approaches</a><a id="Moment-Based-Approaches-1"></a><a class="docs-heading-anchor-permalink" href="#Moment-Based-Approaches" title="Permalink"></a></h3><div class="admonition is-info" id="Emerging-Direction-ff845b0b83e86e02"><header class="admonition-header">Emerging Direction<a class="admonition-anchor" href="#Emerging-Direction-ff845b0b83e86e02" title="Permalink"></a></header><div class="admonition-body"><p>Moment-based GMM estimators (Keweloh 2021, Lanne &amp; Luoto 2021) exploit coskewness and cokurtosis conditions directly, without specifying a parametric distribution. These use conditions like:</p><ul><li><span>$E[\varepsilon_i^2 \varepsilon_j] = 0$</span> (coskewness)</li><li><span>$E[\varepsilon_i^2 \varepsilon_j^2] - 1 = 0$</span>, <span>$E[\varepsilon_i^3 \varepsilon_j] = 0$</span> (cokurtosis)</li></ul><p>This is an important emerging direction in the literature. See Lewis (2025, Section 4.3) for a comprehensive discussion. Not yet implemented in this package.</p></div></div><h3 id="ICA-/-ML-Result-Fields"><a class="docs-heading-anchor" href="#ICA-/-ML-Result-Fields">ICA / ML Result Fields</a><a id="ICA-/-ML-Result-Fields-1"></a><a class="docs-heading-anchor-permalink" href="#ICA-/-ML-Result-Fields" title="Permalink"></a></h3><p><strong>ICA</strong> (<code>ICASVARResult</code>):</p><table><tr><th style="text-align: right">Field</th><th style="text-align: right">Type</th><th style="text-align: right">Description</th></tr><tr><td style="text-align: right"><code>B0</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Structural impact matrix (<span>$n \times n$</span>)</td></tr><tr><td style="text-align: right"><code>W</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Unmixing matrix: <span>$\varepsilon_t = W u_t$</span></td></tr><tr><td style="text-align: right"><code>Q</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Rotation matrix: <span>$B_0 = L Q$</span></td></tr><tr><td style="text-align: right"><code>shocks</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Recovered structural shocks (<span>$T \times n$</span>)</td></tr><tr><td style="text-align: right"><code>method</code></td><td style="text-align: right"><code>Symbol</code></td><td style="text-align: right">Method used</td></tr><tr><td style="text-align: right"><code>converged</code></td><td style="text-align: right"><code>Bool</code></td><td style="text-align: right">Whether the algorithm converged</td></tr><tr><td style="text-align: right"><code>iterations</code></td><td style="text-align: right"><code>Int</code></td><td style="text-align: right">Number of iterations</td></tr><tr><td style="text-align: right"><code>objective</code></td><td style="text-align: right"><code>T</code></td><td style="text-align: right">Final objective value</td></tr></table><p><strong>ML</strong> (<code>NonGaussianMLResult</code>):</p><table><tr><th style="text-align: right">Field</th><th style="text-align: right">Type</th><th style="text-align: right">Description</th></tr><tr><td style="text-align: right"><code>B0</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Structural impact matrix</td></tr><tr><td style="text-align: right"><code>Q</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Rotation matrix</td></tr><tr><td style="text-align: right"><code>shocks</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Structural shocks</td></tr><tr><td style="text-align: right"><code>distribution</code></td><td style="text-align: right"><code>Symbol</code></td><td style="text-align: right">Distribution used</td></tr><tr><td style="text-align: right"><code>loglik</code></td><td style="text-align: right"><code>T</code></td><td style="text-align: right">Log-likelihood at MLE</td></tr><tr><td style="text-align: right"><code>loglik_gaussian</code></td><td style="text-align: right"><code>T</code></td><td style="text-align: right">Gaussian log-likelihood (for LR test)</td></tr><tr><td style="text-align: right"><code>dist_params</code></td><td style="text-align: right"><code>Dict{Symbol,Any}</code></td><td style="text-align: right">Distribution parameters</td></tr><tr><td style="text-align: right"><code>vcov</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Asymptotic covariance of parameters</td></tr><tr><td style="text-align: right"><code>se</code></td><td style="text-align: right"><code>Matrix{T}</code></td><td style="text-align: right">Standard errors for <span>$B_0$</span></td></tr><tr><td style="text-align: right"><code>converged</code></td><td style="text-align: right"><code>Bool</code></td><td style="text-align: right">Convergence status</td></tr><tr><td style="text-align: right"><code>aic</code></td><td style="text-align: right"><code>T</code></td><td style="text-align: right">Akaike information criterion</td></tr><tr><td style="text-align: right"><code>bic</code></td><td style="text-align: right"><code>T</code></td><td style="text-align: right">Bayesian information criterion</td></tr></table><hr/><h2 id="Multivariate-Normality-Tests"><a class="docs-heading-anchor" href="#Multivariate-Normality-Tests">Multivariate Normality Tests</a><a id="Multivariate-Normality-Tests-1"></a><a class="docs-heading-anchor-permalink" href="#Multivariate-Normality-Tests" title="Permalink"></a></h2><p>Before applying non-Gaussian SVAR methods, it is essential to verify that the VAR residuals are indeed non-Gaussian. If residuals are Gaussian, non-Gaussian identification will not work (the problem is unidentified). These tests also serve as a prerequisite diagnostic for choosing between heteroskedasticity-based and non-Gaussianity-based approaches.</p><h3 id="Multivariate-Jarque-Bera-Test"><a class="docs-heading-anchor" href="#Multivariate-Jarque-Bera-Test">Multivariate Jarque-Bera Test</a><a id="Multivariate-Jarque-Bera-Test-1"></a><a class="docs-heading-anchor-permalink" href="#Multivariate-Jarque-Bera-Test" title="Permalink"></a></h3><p>The multivariate Jarque-Bera test extends the univariate JB test to vector residuals. Under the null hypothesis of multivariate normality, the test statistic is:</p><p class="math-container">\[JB = T \cdot \frac{b_{1,k}}{6} + T \cdot \frac{(b_{2,k} - k(k+2))^2}{24k}\]</p><p>where <span>$b_{1,k}$</span> is the multivariate skewness measure and <span>$b_{2,k}$</span> is the multivariate kurtosis measure (Lütkepohl 2005, §4.5).</p><pre><code class="language-julia hljs">using MacroEconometricModels

# Load FRED-MD monetary policy model
fred = load_example(:fred_md)
Y = to_matrix(apply_tcode(fred[:, [&quot;INDPRO&quot;, &quot;CPIAUCSL&quot;, &quot;FEDFUNDS&quot;]]))
Y = Y[all.(isfinite, eachrow(Y)), :]
model = estimate_var(Y, 2)

# Joint test
jb = jarque_bera_test(model)
println(&quot;Statistic: $(round(jb.statistic, digits=4)), p-value: $(round(jb.pvalue, digits=4))&quot;)

# Component-wise test on standardized residuals
jb_comp = jarque_bera_test(model; method=:component)
println(&quot;Component p-values: &quot;, round.(jb_comp.component_pvalues, digits=4))</code></pre><p>With macroeconomic data, non-normality is common — rejecting the null supports using non-Gaussian SVAR methods below.</p><h3 id="Mardia&#39;s-Tests"><a class="docs-heading-anchor" href="#Mardia&#39;s-Tests">Mardia&#39;s Tests</a><a id="Mardia&#39;s-Tests-1"></a><a class="docs-heading-anchor-permalink" href="#Mardia&#39;s-Tests" title="Permalink"></a></h3><p>Mardia (1970) proposed separate tests for multivariate skewness and kurtosis:</p><p class="math-container">\[b_{1,k} = \frac{1}{T^2} \sum_{i,j} (u_i&#39; \Sigma^{-1} u_j)^3 \quad \text{(skewness)}\]</p><p class="math-container">\[b_{2,k} = \frac{1}{T} \sum_i (u_i&#39; \Sigma^{-1} u_i)^2 \quad \text{(kurtosis)}\]</p><p>Under H₀: <span>$T \cdot b_{1,k}/6 \sim \chi^2(k(k+1)(k+2)/6)$</span> and <span>$(b_{2,k} - k(k+2)) / \sqrt{8k(k+2)/T} \sim N(0,1)$</span>.</p><pre><code class="language-julia hljs">skew_test = mardia_test(model; type=:skewness)
kurt_test = mardia_test(model; type=:kurtosis)
both_test = mardia_test(model; type=:both)</code></pre><p>The <code>:both</code> option combines both tests into a single chi-squared statistic.</p><p><strong>Reference</strong>: Mardia (1970)</p><h3 id="Doornik-Hansen-Test"><a class="docs-heading-anchor" href="#Doornik-Hansen-Test">Doornik-Hansen Test</a><a id="Doornik-Hansen-Test-1"></a><a class="docs-heading-anchor-permalink" href="#Doornik-Hansen-Test" title="Permalink"></a></h3><p>The Doornik-Hansen (2008) omnibus test applies the Bowman-Shenton transformation to each component&#39;s skewness and kurtosis, producing approximately standard normal transforms <span>$z_1$</span> and <span>$z_2$</span>. The test statistic is:</p><p class="math-container">\[DH = \sum_{j=1}^k (z_{1j}^2 + z_{2j}^2) \sim \chi^2(2k)\]</p><pre><code class="language-julia hljs">dh = doornik_hansen_test(model)</code></pre><h3 id="Henze-Zirkler-Test"><a class="docs-heading-anchor" href="#Henze-Zirkler-Test">Henze-Zirkler Test</a><a id="Henze-Zirkler-Test-1"></a><a class="docs-heading-anchor-permalink" href="#Henze-Zirkler-Test" title="Permalink"></a></h3><p>The Henze-Zirkler (1990) test is based on the empirical characteristic function and is consistent against all alternatives. The test statistic uses a smoothing parameter <span>$\beta$</span> that depends on the sample size and dimension.</p><pre><code class="language-julia hljs">hz = henze_zirkler_test(model)</code></pre><h3 id="Normality-Test-Suite"><a class="docs-heading-anchor" href="#Normality-Test-Suite">Normality Test Suite</a><a id="Normality-Test-Suite-1"></a><a class="docs-heading-anchor-permalink" href="#Normality-Test-Suite" title="Permalink"></a></h3><p>Run all tests at once with <code>normality_test_suite</code>:</p><pre><code class="language-julia hljs">suite = normality_test_suite(model)
println(suite)</code></pre><p>This runs 7 tests: multivariate JB, component-wise JB, Mardia skewness, Mardia kurtosis, Mardia combined, Doornik-Hansen, and Henze-Zirkler.</p><h3 id="Return-Values"><a class="docs-heading-anchor" href="#Return-Values">Return Values</a><a id="Return-Values-1"></a><a class="docs-heading-anchor-permalink" href="#Return-Values" title="Permalink"></a></h3><table><tr><th style="text-align: right">Field</th><th style="text-align: right">Type</th><th style="text-align: right">Description</th></tr><tr><td style="text-align: right"><code>test_name</code></td><td style="text-align: right"><code>Symbol</code></td><td style="text-align: right">Test identifier</td></tr><tr><td style="text-align: right"><code>statistic</code></td><td style="text-align: right"><code>T</code></td><td style="text-align: right">Test statistic value</td></tr><tr><td style="text-align: right"><code>pvalue</code></td><td style="text-align: right"><code>T</code></td><td style="text-align: right">p-value</td></tr><tr><td style="text-align: right"><code>df</code></td><td style="text-align: right"><code>Int</code></td><td style="text-align: right">Degrees of freedom</td></tr><tr><td style="text-align: right"><code>n_vars</code></td><td style="text-align: right"><code>Int</code></td><td style="text-align: right">Number of variables</td></tr><tr><td style="text-align: right"><code>n_obs</code></td><td style="text-align: right"><code>Int</code></td><td style="text-align: right">Number of observations</td></tr><tr><td style="text-align: right"><code>components</code></td><td style="text-align: right"><code>Vector{T}</code> or <code>nothing</code></td><td style="text-align: right">Per-component statistics</td></tr><tr><td style="text-align: right"><code>component_pvalues</code></td><td style="text-align: right"><code>Vector{T}</code> or <code>nothing</code></td><td style="text-align: right">Per-component p-values</td></tr></table><hr/><h2 id="Identifiability-and-Specification-Tests"><a class="docs-heading-anchor" href="#Identifiability-and-Specification-Tests">Identifiability and Specification Tests</a><a id="Identifiability-and-Specification-Tests-1"></a><a class="docs-heading-anchor-permalink" href="#Identifiability-and-Specification-Tests" title="Permalink"></a></h2><h3 id="Shock-Gaussianity-Test"><a class="docs-heading-anchor" href="#Shock-Gaussianity-Test">Shock Gaussianity Test</a><a id="Shock-Gaussianity-Test-1"></a><a class="docs-heading-anchor-permalink" href="#Shock-Gaussianity-Test" title="Permalink"></a></h3><p>Tests whether recovered structural shocks are non-Gaussian using univariate Jarque-Bera tests on each shock. Non-Gaussian identification requires at most one Gaussian shock.</p><pre><code class="language-julia hljs">ica = identify_fastica(model)
result = test_shock_gaussianity(ica)
println(&quot;Number of Gaussian shocks: &quot;, result.details[:n_gaussian])
println(&quot;Identified: &quot;, result.identified)</code></pre><h3 id="Gaussian-vs-Non-Gaussian-LR-Test"><a class="docs-heading-anchor" href="#Gaussian-vs-Non-Gaussian-LR-Test">Gaussian vs Non-Gaussian LR Test</a><a id="Gaussian-vs-Non-Gaussian-LR-Test-1"></a><a class="docs-heading-anchor-permalink" href="#Gaussian-vs-Non-Gaussian-LR-Test" title="Permalink"></a></h3><p>Likelihood ratio test: <span>$H_0$</span>: Gaussian shocks vs <span>$H_1$</span>: non-Gaussian shocks.</p><p class="math-container">\[LR = 2(\ell_1 - \ell_0) \sim \chi^2(p)\]</p><p>where <span>$p$</span> is the number of extra distribution parameters.</p><pre><code class="language-julia hljs">lr = test_gaussian_vs_nongaussian(model; distribution=:student_t)
println(&quot;LR statistic: $(round(lr.statistic, digits=4))&quot;)
println(&quot;p-value: $(round(lr.pvalue, digits=4))&quot;)</code></pre><p>Rejecting <span>$H_0$</span> supports the use of non-Gaussian identification.</p><h3 id="Shock-Independence-Test"><a class="docs-heading-anchor" href="#Shock-Independence-Test">Shock Independence Test</a><a id="Shock-Independence-Test-1"></a><a class="docs-heading-anchor-permalink" href="#Shock-Independence-Test" title="Permalink"></a></h3><p>Tests whether recovered shocks are mutually independent using both cross-correlation (portmanteau) and distance covariance tests, combined via Fisher&#39;s method.</p><pre><code class="language-julia hljs">result = test_shock_independence(ica; max_lag=10)
println(&quot;Independent: &quot;, result.identified)  # fail-to-reject = independent</code></pre><h3 id="Identification-Strength"><a class="docs-heading-anchor" href="#Identification-Strength">Identification Strength</a><a id="Identification-Strength-1"></a><a class="docs-heading-anchor-permalink" href="#Identification-Strength" title="Permalink"></a></h3><p>Bootstrap test of identification robustness: resamples residuals and measures the stability of the estimated <span>$B_0$</span>.</p><pre><code class="language-julia hljs">result = test_identification_strength(model; method=:fastica, n_bootstrap=499)
println(&quot;Median Procrustes distance: $(round(result.statistic, digits=4))&quot;)</code></pre><p>Small distances indicate strong identification.</p><h3 id="Overidentification-Test"><a class="docs-heading-anchor" href="#Overidentification-Test">Overidentification Test</a><a id="Overidentification-Test-1"></a><a class="docs-heading-anchor-permalink" href="#Overidentification-Test" title="Permalink"></a></h3><p>Tests consistency of additional restrictions beyond non-Gaussianity.</p><pre><code class="language-julia hljs">result = test_overidentification(model, ica; n_bootstrap=499)
println(&quot;p-value: $(round(result.pvalue, digits=4))&quot;)</code></pre><h3 id="Weak-Identification"><a class="docs-heading-anchor" href="#Weak-Identification">Weak Identification</a><a id="Weak-Identification-1"></a><a class="docs-heading-anchor-permalink" href="#Weak-Identification" title="Permalink"></a></h3><div class="admonition is-warning" id="Weak-Identification-99891287e96c7951"><header class="admonition-header">Weak Identification<a class="admonition-anchor" href="#Weak-Identification-99891287e96c7951" title="Permalink"></a></header><div class="admonition-body"><p>Lewis (2022) shows that weak identification is likely in many empirical applications. When variances change little across regimes, or deviations from Gaussianity are small, the identifying information may be weak. In such cases:</p><ul><li>Standard Wald tests may have poor size properties</li><li>Confidence intervals may be unreliable</li><li>Point estimates may be sensitive to specification choices</li></ul><p>Diagnostic checks (identification strength test, shock gaussianity test) are essential. See Lewis (2022) for robust inference procedures.</p></div></div><hr/><h2 id="Integration-with-IRF-Pipeline"><a class="docs-heading-anchor" href="#Integration-with-IRF-Pipeline">Integration with IRF Pipeline</a><a id="Integration-with-IRF-Pipeline-1"></a><a class="docs-heading-anchor-permalink" href="#Integration-with-IRF-Pipeline" title="Permalink"></a></h2><p>All ICA, ML, and heteroskedasticity methods integrate seamlessly with the existing <code>irf</code>, <code>fevd</code>, and <code>historical_decomposition</code> functions via <code>compute_Q</code>:</p><pre><code class="language-julia hljs"># Any statistical identification method works as an irf method
irfs_ica = irf(model, 20; method=:fastica)
irfs_ml  = irf(model, 20; method=:student_t)
irfs_ms  = irf(model, 20; method=:markov_switching)

# FEVD and HD also work
decomp = fevd(model, 20; method=:fastica)</code></pre><p>Supported method symbols: <code>:fastica</code>, <code>:jade</code>, <code>:sobi</code>, <code>:dcov</code>, <code>:hsic</code>, <code>:student_t</code>, <code>:mixture_normal</code>, <code>:pml</code>, <code>:skew_normal</code>, <code>:markov_switching</code>, <code>:garch</code>.</p><hr/><h2 id="The-Labeling-Problem"><a class="docs-heading-anchor" href="#The-Labeling-Problem">The Labeling Problem</a><a id="The-Labeling-Problem-1"></a><a class="docs-heading-anchor-permalink" href="#The-Labeling-Problem" title="Permalink"></a></h2><p>Statistical identification (both heteroskedasticity and non-Gaussianity) identifies <span>$B_0$</span> only up to <strong>column permutation and sign</strong>. The columns of <span>$B_0$</span> represent structural shocks, but the data alone cannot tell us which column corresponds to which economic shock.</p><p>This means:</p><ul><li>Economic information is still needed to <strong>label</strong> shocks (e.g., &quot;this is the monetary policy shock&quot;)</li><li>Our convention: positive diagonal of <span>$B_0$</span> (sign normalization)</li><li>Column ordering may differ across bootstrap replications — the Procrustes distance in <code>test_identification_strength</code> accounts for this</li></ul><p>See Lewis (2025, Section 6.4) for a thorough discussion of the labeling problem.</p><hr/><h2 id="Complete-Example"><a class="docs-heading-anchor" href="#Complete-Example">Complete Example</a><a id="Complete-Example-1"></a><a class="docs-heading-anchor-permalink" href="#Complete-Example" title="Permalink"></a></h2><pre><code class="language-julia hljs">using MacroEconometricModels

# Load FRED-MD monetary policy model
fred = load_example(:fred_md)
Y = to_matrix(apply_tcode(fred[:, [&quot;INDPRO&quot;, &quot;CPIAUCSL&quot;, &quot;FEDFUNDS&quot;]]))
Y = Y[all.(isfinite, eachrow(Y)), :]
model = estimate_var(Y, 2)

# Step 1: Test for non-Gaussianity of VAR residuals
suite = normality_test_suite(model)
println(suite)

# Step 2: Try ICA identification (non-Gaussianity approach)
ica = identify_fastica(model)
println(&quot;\nFastICA result:&quot;)
println(&quot;  Converged: &quot;, ica.converged)
println(&quot;  Q orthogonal: &quot;, round(norm(ica.Q&#39; * ica.Q - I), digits=8))

# Step 3: Verify identification
gauss = test_shock_gaussianity(ica)
println(&quot;\nShock Gaussianity Test:&quot;)
println(&quot;  Number of Gaussian shocks: &quot;, gauss.details[:n_gaussian])
println(&quot;  JB p-values: &quot;, round.(gauss.details[:jb_pvals], digits=4))

indep = test_shock_independence(ica; max_lag=5)
println(&quot;\nShock Independence Test:&quot;)
println(&quot;  Independent: &quot;, indep.identified)
println(&quot;  Fisher p-value: &quot;, round(indep.pvalue, digits=4))

# Step 4: Compare with ML approach (non-Gaussianity, parametric)
ml = identify_student_t(model)
println(&quot;\nStudent-t ML:&quot;)
println(&quot;  ν = &quot;, round.(ml.dist_params[:nu], digits=2))
println(&quot;  AIC = $(round(ml.aic, digits=2)), BIC = $(round(ml.bic, digits=2))&quot;)

lr = test_gaussian_vs_nongaussian(model)
println(&quot;\nGaussian vs Non-Gaussian LR test:&quot;)
println(&quot;  LR = $(round(lr.statistic, digits=4)), p = $(round(lr.pvalue, digits=4))&quot;)

# Step 5: Try heteroskedasticity approach
ms = identify_markov_switching(model; n_regimes=2)
println(&quot;\nMarkov-switching identification:&quot;)
println(&quot;  Converged: &quot;, ms.converged)
println(&quot;  Log-likelihood: &quot;, round(ms.loglik, digits=2))

# Step 6: Compute IRFs using preferred method
irfs = irf(model, 20; method=:fastica)
println(&quot;\nIRF size: &quot;, size(irfs.values))</code></pre><hr/><h3 id="See-Also"><a class="docs-heading-anchor" href="#See-Also">See Also</a><a id="See-Also-1"></a><a class="docs-heading-anchor-permalink" href="#See-Also" title="Permalink"></a></h3><ul><li><a href="../manual/">VAR Estimation</a> – Reduced-form VAR and traditional identification methods</li><li><a href="../hypothesis_tests/">Hypothesis Tests</a> – Normality tests for residual diagnostics</li><li><a href="../innovation_accounting/">Innovation Accounting</a> – IRF, FEVD, and historical decomposition</li><li><a href="../api_functions/">API Reference</a> – Complete function signatures</li></ul><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><h3 id="Survey"><a class="docs-heading-anchor" href="#Survey">Survey</a><a id="Survey-1"></a><a class="docs-heading-anchor-permalink" href="#Survey" title="Permalink"></a></h3><ul><li>Lewis, Daniel J. 2025. &quot;Identification Based on Higher Moments in Macroeconometrics.&quot; <em>Annual Review of Economics</em> 17: 665–693. <a href="https://doi.org/10.1146/annurev-economics-070124-051419">https://doi.org/10.1146/annurev-economics-070124-051419</a></li></ul><h3 id="Heteroskedasticity-Based-Identification"><a class="docs-heading-anchor" href="#Heteroskedasticity-Based-Identification">Heteroskedasticity-Based Identification</a><a id="Heteroskedasticity-Based-Identification-1"></a><a class="docs-heading-anchor-permalink" href="#Heteroskedasticity-Based-Identification" title="Permalink"></a></h3><ul><li>Rigobon, Roberto. 2003. &quot;Identification through Heteroskedasticity.&quot; <em>Review of Economics and Statistics</em> 85 (4): 777–792. <a href="https://doi.org/10.1162/003465303772815727">https://doi.org/10.1162/003465303772815727</a></li><li>Sentana, Enrique, and Gabriele Fiorentini. 2001. &quot;Identification, Estimation and Testing of Conditionally Heteroskedastic Factor Models.&quot; <em>Journal of Econometrics</em> 102 (2): 143–164. <a href="https://doi.org/10.1016/S0304-4076(01)00051-3">https://doi.org/10.1016/S0304-4076(01)00051-3</a></li><li>Lanne, Markku, and Helmut Lütkepohl. 2008. &quot;Identifying Monetary Policy Shocks via Changes in Volatility.&quot; <em>Journal of Money, Credit and Banking</em> 40 (6): 1131–1149. <a href="https://doi.org/10.1111/j.1538-4616.2008.00151.x">https://doi.org/10.1111/j.1538-4616.2008.00151.x</a></li><li>Normandin, Michel, and Louis Phaneuf. 2004. &quot;Monetary Policy Shocks: Testing Identification Conditions under Time-Varying Conditional Volatility.&quot; <em>Journal of Monetary Economics</em> 51 (6): 1217–1243. <a href="https://doi.org/10.1016/j.jmoneco.2003.11.002">https://doi.org/10.1016/j.jmoneco.2003.11.002</a></li><li>Lütkepohl, Helmut, and Aleksei Netšunajev. 2017. &quot;Structural Vector Autoregressions with Smooth Transition in Variances.&quot; <em>Journal of Economic Dynamics and Control</em> 84: 43–57. <a href="https://doi.org/10.1016/j.jedc.2017.09.001">https://doi.org/10.1016/j.jedc.2017.09.001</a></li><li>Lewis, Daniel J. 2021. &quot;Identifying Shocks via Time-Varying Volatility.&quot; <em>Review of Economic Studies</em> 88 (6): 3086–3124. <a href="https://doi.org/10.1093/restud/rdab009">https://doi.org/10.1093/restud/rdab009</a></li></ul><h3 id="Non-Gaussianity-—-ICA-(Nonparametric)"><a class="docs-heading-anchor" href="#Non-Gaussianity-—-ICA-(Nonparametric)">Non-Gaussianity — ICA (Nonparametric)</a><a id="Non-Gaussianity-—-ICA-(Nonparametric)-1"></a><a class="docs-heading-anchor-permalink" href="#Non-Gaussianity-—-ICA-(Nonparametric)" title="Permalink"></a></h3><ul><li>Hyvärinen, Aapo. 1999. &quot;Fast and Robust Fixed-Point Algorithms for Independent Component Analysis.&quot; <em>IEEE Transactions on Neural Networks</em> 10 (3): 626–634. <a href="https://doi.org/10.1109/72.761722">https://doi.org/10.1109/72.761722</a></li><li>Cardoso, Jean-François, and Antoine Souloumiac. 1993. &quot;Blind Beamforming for Non-Gaussian Signals.&quot; <em>IEE Proceedings-F</em> 140 (6): 362–370. <a href="https://doi.org/10.1049/ip-f-2.1993.0054">https://doi.org/10.1049/ip-f-2.1993.0054</a></li><li>Belouchrani, Adel, Karim Abed-Meraim, Jean-François Cardoso, and Eric Moulines. 1997. &quot;A Blind Source Separation Technique Using Second-Order Statistics.&quot; <em>IEEE Transactions on Signal Processing</em> 45 (2): 434–444. <a href="https://doi.org/10.1109/78.554307">https://doi.org/10.1109/78.554307</a></li><li>Comon, Pierre. 1994. &quot;Independent Component Analysis, A New Concept?&quot; <em>Signal Processing</em> 36 (3): 287–314. <a href="https://doi.org/10.1016/0165-1684(94)90029-9">https://doi.org/10.1016/0165-1684(94)90029-9</a></li></ul><h3 id="Non-Gaussianity-—-ML-(Parametric)"><a class="docs-heading-anchor" href="#Non-Gaussianity-—-ML-(Parametric)">Non-Gaussianity — ML (Parametric)</a><a id="Non-Gaussianity-—-ML-(Parametric)-1"></a><a class="docs-heading-anchor-permalink" href="#Non-Gaussianity-—-ML-(Parametric)" title="Permalink"></a></h3><ul><li>Lanne, Markku, Mika Meitz, and Pentti Saikkonen. 2017. &quot;Identification and Estimation of Non-Gaussian Structural Vector Autoregressions.&quot; <em>Journal of Econometrics</em> 196 (2): 288–304. <a href="https://doi.org/10.1016/j.jeconom.2016.06.002">https://doi.org/10.1016/j.jeconom.2016.06.002</a></li><li>Gourieroux, Christian, Alain Monfort, and Jean-Paul Renne. 2017. &quot;Statistical Inference for Independent Component Analysis: Application to Structural VAR Models.&quot; <em>Journal of Econometrics</em> 196 (1): 111–126. <a href="https://doi.org/10.1016/j.jeconom.2016.09.007">https://doi.org/10.1016/j.jeconom.2016.09.007</a></li><li>Lanne, Markku, and Helmut Lütkepohl. 2010. &quot;Structural Vector Autoregressions with Nonnormal Residuals.&quot; <em>Journal of Business &amp; Economic Statistics</em> 28 (1): 159–168. <a href="https://doi.org/10.1198/jbes.2009.06003">https://doi.org/10.1198/jbes.2009.06003</a></li><li>Herwartz, Helmut. 2018. &quot;Hodges-Lehmann Detection of Structural Shocks: An Analysis of Macroeconomic Dynamics in the Euro Area.&quot; <em>Oxford Bulletin of Economics and Statistics</em> 80 (4): 736–754. <a href="https://doi.org/10.1111/obes.12234">https://doi.org/10.1111/obes.12234</a></li><li>Azzalini, Adelchi. 1985. &quot;A Class of Distributions Which Includes the Normal Ones.&quot; <em>Scandinavian Journal of Statistics</em> 12 (2): 171–178. <a href="https://www.jstor.org/stable/4615982">https://www.jstor.org/stable/4615982</a></li></ul><h3 id="Non-Gaussianity-—-Moments-(GMM)"><a class="docs-heading-anchor" href="#Non-Gaussianity-—-Moments-(GMM)">Non-Gaussianity — Moments (GMM)</a><a id="Non-Gaussianity-—-Moments-(GMM)-1"></a><a class="docs-heading-anchor-permalink" href="#Non-Gaussianity-—-Moments-(GMM)" title="Permalink"></a></h3><ul><li>Keweloh, Sascha A. 2021. &quot;A Generalized Method of Moments Estimator for Structural Vector Autoregressions Based on Higher Moments.&quot; <em>Journal of Business &amp; Economic Statistics</em> 39 (3): 772–882. <a href="https://doi.org/10.1080/07350015.2020.1730858">https://doi.org/10.1080/07350015.2020.1730858</a></li><li>Lanne, Markku, and Jani Luoto. 2021. &quot;GMM Estimation of Non-Gaussian Structural Vector Autoregression.&quot; <em>Journal of Business &amp; Economic Statistics</em> 39 (1): 69–81. <a href="https://doi.org/10.1080/07350015.2019.1629940">https://doi.org/10.1080/07350015.2019.1629940</a></li></ul><h3 id="Diagnostics-and-Weak-Identification"><a class="docs-heading-anchor" href="#Diagnostics-and-Weak-Identification">Diagnostics and Weak Identification</a><a id="Diagnostics-and-Weak-Identification-1"></a><a class="docs-heading-anchor-permalink" href="#Diagnostics-and-Weak-Identification" title="Permalink"></a></h3><ul><li>Lewis, Daniel J. 2022. &quot;Robust Inference in Models Identified via Heteroskedasticity.&quot; <em>Review of Economics and Statistics</em> 104 (3): 510–524. <a href="https://doi.org/10.1162/rest_a_00977">https://doi.org/10.1162/rest<em>a</em>00977</a></li></ul><h3 id="Multivariate-Normality-Tests-2"><a class="docs-heading-anchor" href="#Multivariate-Normality-Tests-2">Multivariate Normality Tests</a><a class="docs-heading-anchor-permalink" href="#Multivariate-Normality-Tests-2" title="Permalink"></a></h3><ul><li>Jarque, Carlos M., and Anil K. Bera. 1980. &quot;Efficient Tests for Normality, Homoscedasticity and Serial Independence of Regression Residuals.&quot; <em>Economics Letters</em> 6 (3): 255–259. <a href="https://doi.org/10.1016/0165-1765(80)90024-5">https://doi.org/10.1016/0165-1765(80)90024-5</a></li><li>Mardia, Kanti V. 1970. &quot;Measures of Multivariate Skewness and Kurtosis with Applications.&quot; <em>Biometrika</em> 57 (3): 519–530. <a href="https://doi.org/10.1093/biomet/57.3.519">https://doi.org/10.1093/biomet/57.3.519</a></li><li>Doornik, Jurgen A., and Henrik Hansen. 2008. &quot;An Omnibus Test for Univariate and Multivariate Normality.&quot; <em>Oxford Bulletin of Economics and Statistics</em> 70: 927–939. <a href="https://doi.org/10.1111/j.1468-0084.2008.00537.x">https://doi.org/10.1111/j.1468-0084.2008.00537.x</a></li><li>Henze, Norbert, and Bernhard Zirkler. 1990. &quot;A Class of Invariant Consistent Tests for Multivariate Normality.&quot; <em>Communications in Statistics - Theory and Methods</em> 19 (10): 3595–3617. <a href="https://doi.org/10.1080/03610929008830400">https://doi.org/10.1080/03610929008830400</a></li><li>Lütkepohl, Helmut. 2005. <em>New Introduction to Multiple Time Series Analysis</em>. Berlin: Springer. ISBN 978-3-540-40172-8.</li></ul><h3 id="Independence-Measures"><a class="docs-heading-anchor" href="#Independence-Measures">Independence Measures</a><a id="Independence-Measures-1"></a><a class="docs-heading-anchor-permalink" href="#Independence-Measures" title="Permalink"></a></h3><ul><li>Székely, Gábor J., Maria L. Rizzo, and Nail K. Bakirov. 2007. &quot;Measuring and Testing Dependence by Correlation of Distances.&quot; <em>Annals of Statistics</em> 35 (6): 2769–2794. <a href="https://doi.org/10.1214/009053607000000505">https://doi.org/10.1214/009053607000000505</a></li><li>Gretton, Arthur, Olivier Bousquet, Alex Smola, and Bernhard Schölkopf. 2005. &quot;Measuring Statistical Dependence with Hilbert-Schmidt Norms.&quot; In <em>Algorithmic Learning Theory</em>, edited by Sanjay Jain, Hans Ulrich Simon, and Etsuji Tomita, 63–77. Berlin: Springer. <a href="https://doi.org/10.1007/11564089_7">https://doi.org/10.1007/11564089_7</a></li><li>Matteson, David S., and Ruey S. Tsay. 2017. &quot;Independent Component Analysis via Distance Covariance.&quot; <em>Journal of the American Statistical Association</em> 112 (518): 623–637. <a href="https://doi.org/10.1080/01621459.2016.1150851">https://doi.org/10.1080/01621459.2016.1150851</a></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../nowcast/">« Nowcasting</a><a class="docs-footer-nextpage" href="../hypothesis_tests/">Hypothesis Tests »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Friday 20 February 2026 19:11">Friday 20 February 2026</span>. Using Julia version 1.10.10.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
