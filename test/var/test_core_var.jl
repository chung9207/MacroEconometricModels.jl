using MacroEconometricModels
using Test
using LinearAlgebra
using Statistics
using DataFrames
using Random

@testset "Core VAR & Identification" begin
    # Use fixed seed for reproducibility
    Random.seed!(12345)

    # 1. Generate Synthetic Data
    T = 200
    n = 2
    p = 1

    true_A = [0.5 0.0; 0.0 0.5] # Diagonal AR
    true_c = [0.0; 0.0]
    Sigma_true = [1.0 0.0; 0.0 1.0] # Identity

    Y = zeros(T, n)
    # Generate data
    for t in 2:T
        u = randn(2)
        Y[t, :] = true_c + true_A * Y[t-1, :] + u
    end

    # 2. Estimate
    model = estimate_var(Y, p)

    # 6. Identification (Cholesky)
    L = identify_cholesky(model)
    @test istriu(L')

    # 7. Sign Restrictions
    # We want to identify a "positive shock" to variable 1
    # Restriction: Response of Var 1 to Shock 1 at h=0 is positive (> 0)

    horizon = 10
    check_func(irf) = irf[1, 1, 1] > 0

    Q_sign, irf_sign = identify_sign(model, horizon, check_func)
    @test irf_sign[1, 1, 1] > 0
    @test isapprox(Q_sign * Q_sign', I(n), atol=1e-10) # Q is orthogonal

    # 8. Narrative Restrictions
    # Assume we know that at t=5, the shock 1 was positive.
    narrative_check(shocks) = shocks[5, 1] > 0

    Q_nar, irf_nar, shocks_nar = identify_narrative(model, horizon, check_func, narrative_check)
    @test irf_nar[1, 1, 1] > 0
    @test shocks_nar[5, 1] > 0

    # 9. Long Run Identification
    # Blanchard-Quah
    Q_lr = identify_long_run(model)
    @test isapprox(Q_lr * Q_lr', I(n), atol=1e-10)

    # Check if Long Run Impact is Lower Triangular
    # LR Impact = (I - A(1))^-1 * P
    # P = L * Q_lr
    # We can approximate infinite sum IRF or compute directly.
    # IRF cumulative sum at large h should be close to LR impact.

    # Let's compute directly to verify property
    B = model.B
    A_sum = zeros(n, n)
    for i in 1:p
        start_row = 1 + (i - 1) * n + 1
        end_row = 1 + i * n
        A_sum += B[start_row:end_row, :]'
    end
    inv_lag = inv(I(n) - A_sum)
    L_chol = identify_cholesky(model)
    P = L_chol * Q_lr
    LR_Matrix = inv_lag * P

    # Check lower triangularity of LR_Matrix
    @test abs(LR_Matrix[1, 2]) < 1e-8 # Upper right element should be 0

    @testset "Higher Order Lag (VAR(12))" begin
        # Test estimation with long lags using a known DGP to verify statistical recovery
        # DGP: Y_t = A_1 Y_{t-1} + ... + A_{12} Y_{t-12} + u_t
        # A_1 = 0.4 * I
        # A_12 = 0.2 * I
        # Others = 0

        T_large = 2000
        n = 2
        p = 12

        Y = zeros(T_large, n)

        # True Parameters
        A1 = [0.4 0.0; 0.0 0.4]
        A12 = [0.2 0.0; 0.0 0.2]
        Sigma_true = [1.0 0.0; 0.0 1.0]

        # Simulation
        Random.seed!(42) # Ensure reproducibility
        for t in p+1:T_large
            u = randn(n)
            # Y_t = A1 * Y_{t-1} + A12 * Y_{t-12} + u
            Y[t, :] = A1 * Y[t-1, :] + A12 * Y[t-12, :] + u
        end

        # Estimate
        model = estimate_var(Y, p)

        # Verify Coefficients
        # B structure: [Intercept; A_1'; A_2'; ... A_p']
        # Intercept should be close to 0
        @test norm(model.B[1, :]) < 0.2

        # Check Lag 1 (Rows 2:3)
        est_A1 = model.B[2:3, :]'
        @test isapprox(est_A1, A1, atol=0.1)

        # Check Lag 12 (Rows 1+11*2+1 : 1+12*2) -> Rows 24:25
        est_A12 = model.B[end-1:end, :]'
        @test isapprox(est_A12, A12, atol=0.1)

        # Check a middle lag (e.g., Lag 6) is close to zero
        # Rows for Lag 6: 1 + 5*2 + 1 = 12 to 13?
        # Lag k starts at 2 + (k-1)*n
        # Lag 6: 2 + 5*2 = 12. So rows 12:13.
        est_A6 = model.B[12:13, :]'
        @test norm(est_A6) < 0.1

        # Verify Residuals Covariance
        @test isapprox(model.Sigma, Sigma_true, atol=0.1)
    end

    # ==========================================================================
    # Robustness Tests (Following Arias et al. pattern)
    # ==========================================================================

    @testset "Reproducibility" begin
        # Same seed should produce identical results
        Random.seed!(99999)
        Y1 = zeros(100, 2)
        for t in 2:100
            Y1[t, :] = 0.5 * Y1[t-1, :] + randn(2)
        end
        model1 = estimate_var(Y1, 1)

        Random.seed!(99999)
        Y2 = zeros(100, 2)
        for t in 2:100
            Y2[t, :] = 0.5 * Y2[t-1, :] + randn(2)
        end
        model2 = estimate_var(Y2, 1)

        @test model1.B ≈ model2.B
        @test model1.Sigma ≈ model2.Sigma
        @test model1.U ≈ model2.U
    end

    @testset "Stability Check" begin
        # VAR should detect stable vs unstable systems
        Random.seed!(11111)
        T_stab = 200
        n_stab = 2
        p_stab = 1

        # Stable VAR
        Y_stable = zeros(T_stab, n_stab)
        A_stable = [0.3 0.1; 0.1 0.3]  # All eigenvalues < 1
        for t in 2:T_stab
            Y_stable[t, :] = A_stable * Y_stable[t-1, :] + randn(n_stab)
        end
        model_stable = estimate_var(Y_stable, p_stab)

        # Check stability via companion matrix eigenvalues
        F = companion_matrix(model_stable.B, n_stab, p_stab)
        eigenvalues = eigvals(F)
        @test maximum(abs.(eigenvalues)) < 1.0  # Stable
    end

    @testset "Numerical Stability - Near-Collinear Data" begin
        Random.seed!(22222)
        T_nc = 200
        n_nc = 3

        # Create data with near-collinearity
        Y_nc = randn(T_nc, n_nc)
        Y_nc[:, 3] = Y_nc[:, 1] + 0.01 * randn(T_nc)  # Variable 3 ≈ Variable 1

        # Should not crash with near-singular covariance
        model_nc = estimate_var(Y_nc, 1)
        @test model_nc isa VARModel
        @test all(isfinite.(model_nc.B))
        @test all(isfinite.(model_nc.Sigma))
    end

    @testset "Edge Cases" begin
        Random.seed!(33333)

        # Single variable VAR
        Y_single = randn(100, 1)
        model_single = estimate_var(Y_single, 1)
        @test size(model_single.B) == (2, 1)  # intercept + 1 lag
        @test size(model_single.Sigma) == (1, 1)

        # Minimum viable sample size (T just larger than p*n + 1)
        n_min = 2
        p_min = 2
        T_min = p_min * n_min + 10  # Bare minimum observations
        Y_min = randn(T_min, n_min)
        model_min = estimate_var(Y_min, p_min)
        @test model_min isa VARModel

        # VAR(1) - simplest case
        Y_var1 = randn(50, 2)
        model_var1 = estimate_var(Y_var1, 1)
        @test model_var1.p == 1
    end

    @testset "Orthogonality of Q Matrices" begin
        Random.seed!(44444)
        T_q = 150
        n_q = 3
        Y_q = randn(T_q, n_q)
        model_q = estimate_var(Y_q, 1)

        # Cholesky Q should be identity (orthogonal)
        Q_chol = I(n_q)
        @test norm(Q_chol' * Q_chol - I(n_q)) < 1e-10

        # Sign restriction Q should be orthogonal
        check_func_q(irf) = irf[1, 1, 1] > 0
        Q_sign_q, _ = identify_sign(model_q, 5, check_func_q)
        @test norm(Q_sign_q' * Q_sign_q - I(n_q)) < 1e-10
        @test norm(Q_sign_q * Q_sign_q' - I(n_q)) < 1e-10

        # Columns should be unit vectors
        for j in 1:n_q
            @test abs(norm(Q_sign_q[:, j]) - 1.0) < 1e-10
        end
    end

    @testset "Input Validation" begin
        Random.seed!(55555)
        Y_val = randn(100, 2)

        # p = 0 should error or be handled
        @test_throws Exception estimate_var(Y_val, 0)

        # p too large for data - package handles gracefully with warning
        # Just verify it returns a model (even if with adjusted dof)
        model_large_p = estimate_var(Y_val, 40)
        @test model_large_p isa VARModel

        # Empty data
        @test_throws Exception estimate_var(zeros(0, 2), 1)
    end

    # =================================================================
    # Identification Functions (expanded coverage)
    # =================================================================

    @testset "generate_Q properties" begin
        Random.seed!(60000)

        for n in [2, 3, 5]
            Q = MacroEconometricModels.generate_Q(n)
            @test size(Q) == (n, n)

            # Orthogonality: Q'Q ≈ I
            @test isapprox(Q' * Q, Matrix{Float64}(I, n, n), atol=1e-10)
            @test isapprox(Q * Q', Matrix{Float64}(I, n, n), atol=1e-10)

            # Determinant ≈ ±1
            @test isapprox(abs(det(Q)), 1.0, atol=1e-10)

            # Columns are unit vectors
            for j in 1:n
                @test isapprox(norm(Q[:, j]), 1.0, atol=1e-10)
            end
        end

        # Randomness: two Q draws should differ
        Q1 = MacroEconometricModels.generate_Q(3)
        Q2 = MacroEconometricModels.generate_Q(3)
        @test !isapprox(Q1, Q2, atol=1e-5)
    end

    @testset "compute_structural_shocks" begin
        Random.seed!(61000)
        Y = randn(200, 3)
        model = estimate_var(Y, 2)
        n = 3

        # With identity Q (Cholesky identification)
        Q = Matrix{Float64}(I, n, n)
        shocks = MacroEconometricModels.compute_structural_shocks(model, Q)

        T_eff = size(model.U, 1)
        @test size(shocks) == (T_eff, n)
        @test !any(isnan, shocks)

        # Structural shocks should have unit variance (approximately, for Cholesky)
        for j in 1:n
            @test isapprox(var(shocks[:, j]), 1.0, rtol=0.3)
        end

        # With a random orthogonal Q
        Q_rand = MacroEconometricModels.generate_Q(n)
        shocks_rand = MacroEconometricModels.compute_structural_shocks(model, Q_rand)
        @test size(shocks_rand) == (T_eff, n)

        # Structural shocks from random Q should also have approximately unit variance
        for j in 1:n
            @test isapprox(var(shocks_rand[:, j]), 1.0, rtol=0.3)
        end
    end

    @testset "compute_irf" begin
        Random.seed!(62000)
        Y = randn(200, 2)
        model = estimate_var(Y, 1)
        n = 2
        horizon = 10

        # Identity Q
        Q = Matrix{Float64}(I, n, n)
        irf_array = MacroEconometricModels.compute_irf(model, Q, horizon)

        @test size(irf_array) == (horizon, n, n)
        @test !any(isnan, irf_array)

        # Impact (h=1) should be non-zero for a non-degenerate model
        @test any(irf_array[1, :, :] .!= 0)

        # IRF should decay for stationary model
        for i in 1:n, j in 1:n
            @test abs(irf_array[horizon, i, j]) < abs(irf_array[1, i, j]) + 1.0
        end
    end

    @testset "compute_Q dispatcher" begin
        Random.seed!(63000)
        Y = randn(200, 2)
        model = estimate_var(Y, 1)
        n = 2

        # :cholesky
        Q_chol = MacroEconometricModels.compute_Q(model, :cholesky, 10, nothing, nothing)
        @test Q_chol == Matrix{Float64}(I, n, n)

        # :long_run
        Q_lr = MacroEconometricModels.compute_Q(model, :long_run, 10, nothing, nothing)
        @test size(Q_lr) == (n, n)

        # :sign
        check_func = irf -> irf[1, 1, 1] > 0
        Q_sign = MacroEconometricModels.compute_Q(model, :sign, 10, check_func, nothing)
        @test size(Q_sign) == (n, n)
        # Verify the sign restriction is satisfied
        irf_check = MacroEconometricModels.compute_irf(model, Q_sign, 10)
        @test irf_check[1, 1, 1] > 0

        # Invalid method
        @test_throws ArgumentError MacroEconometricModels.compute_Q(model, :invalid, 10, nothing, nothing)

        # :sign without check_func
        @test_throws ArgumentError MacroEconometricModels.compute_Q(model, :sign, 10, nothing, nothing)
    end

    @testset "identify_cholesky" begin
        Random.seed!(64000)
        Y = randn(200, 3)
        model = estimate_var(Y, 1)

        L = identify_cholesky(model)
        @test size(L) == (3, 3)

        # L should be lower triangular
        @test istriu(L')

        # L * L' ≈ Sigma
        @test isapprox(L * L', model.Sigma, atol=1e-8)
    end

    @testset "identify_sign multiple draws" begin
        Random.seed!(65000)
        Y = randn(200, 2)
        model = estimate_var(Y, 1)

        # Multiple draws should all satisfy constraint
        check_func = irf -> irf[1, 1, 1] > 0 && irf[1, 2, 1] > 0
        Q, irf_result = identify_sign(model, 10, check_func; max_draws=5000)

        @test irf_result[1, 1, 1] > 0
        @test irf_result[1, 2, 1] > 0
        @test isapprox(Q' * Q, I(2), atol=1e-10)
    end

    @testset "identify_long_run" begin
        Random.seed!(66000)
        Y = randn(200, 2)
        model = estimate_var(Y, 1)

        Q = identify_long_run(model)
        @test size(Q) == (2, 2)

        # Long-run cumulative impact matrix should be lower triangular
        n, p = 2, 1
        A = MacroEconometricModels.extract_ar_coefficients(model.B, n, p)
        A_sum = sum(A)
        inv_lag = inv(I(n) - A_sum)
        L = MacroEconometricModels.safe_cholesky(model.Sigma)
        C1 = inv_lag * L * Q  # Long-run impact

        # C1 should be approximately lower triangular
        @test abs(C1[1, 2]) < 0.5  # Upper triangle should be small (not exactly zero due to numerics)
    end

    @testset "irf_percentiles and irf_mean" begin
        Random.seed!(67000)
        Y = randn(200, 2)
        model = estimate_var(Y, 1)
        n = 2
        horizon = 8

        # Create sign restrictions for Arias identification
        restrictions = SVARRestrictions(n;
            signs=[sign_restriction(1, 1, :positive; horizon=0)]
        )

        try
            result = MacroEconometricModels.identify_arias(model, restrictions, horizon;
                n_draws=50, n_rotations=500)

            # irf_percentiles
            pct = MacroEconometricModels.irf_percentiles(result; probs=[0.16, 0.5, 0.84])
            @test size(pct) == (horizon, n, n, 3)

            # Percentiles should be ordered
            for h in 1:horizon, i in 1:n, j in 1:n
                @test pct[h, i, j, 1] <= pct[h, i, j, 2]
                @test pct[h, i, j, 2] <= pct[h, i, j, 3]
            end

            # irf_mean
            mean_irf = MacroEconometricModels.irf_mean(result)
            @test size(mean_irf) == (horizon, n, n)
            @test !any(isnan, mean_irf)

        catch e
            @warn "Arias identification test failed (may need more draws)" exception=e
            @test_skip "Arias identification skipped"
        end
    end
end
